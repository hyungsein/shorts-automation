"""
ğŸ¬ Video Agent - Creates final short video with images, TTS, and subtitles
"""

import asyncio
from pathlib import Path

from moviepy import (
    AudioFileClip,
    ColorClip,
    CompositeAudioClip,
    CompositeVideoClip,
    ImageClip,
    TextClip,
    concatenate_videoclips,
)
from moviepy.audio.fx import MultiplyVolume
from PIL import Image
import random

from ..config import settings
from ..models import AudioResult, ImageResult, Script, VideoResult
from .base import BaseAgent


class VideoAgent(BaseAgent[VideoResult]):
    """Agent for creating short videos with images and subtitles"""

    @property
    def name(self) -> str:
        return "ğŸ¬ VideoAgent"

    # Short video dimensions (9:16 aspect ratio)
    WIDTH = 1080
    HEIGHT = 1920

    # BGM í´ë” ê²½ë¡œ
    BGM_DIR = Path(__file__).parent.parent.parent / "assets" / "bgm"

    def _get_bgm(self) -> Path | None:
        """ê³ ì • BGM ë°˜í™˜ (soft_ambient.mp3)"""
        bgm_path = self.BGM_DIR / "soft_ambient.mp3"
        if bgm_path.exists():
            return bgm_path
        return None

    async def run(
            self,
            images: list[ImageResult],
            audio: AudioResult,
            script: Script,
            output_path: Path,
            title: str = None,  # ìƒë‹¨ ì œëª© (ì„ íƒ)
    ) -> VideoResult:
        """Create final short video with images and subtitles"""
        self.log("Creating video...")

        output_path = Path(output_path)
        output_path.parent.mkdir(parents=True, exist_ok=True)

        # Load TTS audio
        tts_clip = AudioFileClip(str(audio.file_path))
        duration = tts_clip.duration

        # Load BGM (ìˆìœ¼ë©´ TTSì™€ ë¯¹ìŠ¤)
        bgm_path = self._get_bgm()
        if bgm_path:
            self.log(f"ğŸµ BGM: {bgm_path.name}")
            bgm_clip = AudioFileClip(str(bgm_path))
            # BGMì„ ì˜ìƒ ê¸¸ì´ì— ë§ê²Œ ìë¥´ê¸°
            if bgm_clip.duration > duration:
                bgm_clip = bgm_clip.subclipped(0, duration)
            else:
                # BGMì´ ì§§ìœ¼ë©´ ë£¨í”„
                from moviepy import concatenate_audioclips
                loops_needed = int(duration / bgm_clip.duration) + 1
                bgm_clips = [
                    AudioFileClip(str(bgm_path)) for _ in range(loops_needed)
                ]
                bgm_clip = concatenate_audioclips(bgm_clips).subclipped(
                    0, duration)
            # BGM ë³¼ë¥¨ ë‚®ì¶”ê¸° (TTSê°€ ë©”ì¸) - 15%
            bgm_clip = bgm_clip.with_effects([MultiplyVolume(0.15)])
            # TTS + BGM ë¯¹ìŠ¤
            audio_clip = CompositeAudioClip([tts_clip, bgm_clip])
        else:
            self.log("âš ï¸ No BGM found in assets/bgm/ folder")
            audio_clip = tts_clip

        # Create image slideshow
        if images:
            bg_clip = self._create_image_slideshow(images, duration)
        else:
            bg_clip = self._create_gradient_background(duration)

        # Generate subtitles
        subtitle_clips = await self._generate_subtitles(script, duration)

        # Generate title (ìƒë‹¨ì— í‘œì‹œ)
        title_clips = []
        if title:
            title_clips = self._create_title_clip(title, duration)

        # Compose final video
        final_clip = CompositeVideoClip([bg_clip] + title_clips +
                                        subtitle_clips,
                                        size=(self.WIDTH, self.HEIGHT))
        final_clip = final_clip.with_audio(audio_clip)

        self.log(f"Audio duration: {audio_clip.duration:.1f}s")

        # Export
        self.log(f"Exporting video to {output_path}...")
        final_clip.write_videofile(
            str(output_path),
            fps=30,
            codec="libx264",
            audio_codec="aac",
            preset="medium",
            threads=4,
            audio=True,  # ì˜¤ë””ì˜¤ í¬í•¨ ëª…ì‹œ
        )

        # Cleanup
        audio_clip.close()
        bg_clip.close()
        final_clip.close()

        self.log(f"Video created: {output_path}")

        return VideoResult(
            file_path=output_path,
            duration=duration,
            resolution=(self.WIDTH, self.HEIGHT),
        )

    def _create_image_slideshow(
        self,
        images: list[ImageResult],
        duration: float,
    ) -> CompositeVideoClip:
        """Create dynamic slideshow with intentional camera effects"""
        if not images:
            return self._create_gradient_background(duration)

        time_per_image = duration / len(images)
        image_clips = []

        for i, img_result in enumerate(images):
            img_path = img_result.file_path

            # Load image
            img_clip = ImageClip(str(img_path))
            img_clip = self._resize_to_fit(img_clip)

            # í”„ë¡¬í”„íŠ¸ì—ì„œ ì¹´ë©”ë¼ íš¨ê³¼ ì¶”ì¶œ (format: "effect|prompt")
            effect_type = "static"
            if "|" in img_result.prompt:
                parts = img_result.prompt.split("|", 1)
                effect_type = parts[0].strip()

            # ìœ íš¨í•œ íš¨ê³¼ì¸ì§€ í™•ì¸ (shake ì œì™¸ - ì–´ì§€ëŸ¬ì›€)
            valid_effects = ["zoom_in", "zoom_out", "static", "fade"]
            if effect_type not in valid_effects:
                effect_type = "static"

            # ì¤Œ/íŒ¬ íš¨ê³¼ ì ìš©
            img_clip = self._apply_dynamic_effect(img_clip, effect_type,
                                                  time_per_image)

            # Set timing
            img_clip = img_clip.with_start(i * time_per_image)
            img_clip = img_clip.with_duration(time_per_image)

            image_clips.append(img_clip)

        # Create background
        bg = ColorClip(
            size=(self.WIDTH, self.HEIGHT),
            color=(15, 15, 20),
            duration=duration,
        )

        return CompositeVideoClip([bg] + image_clips,
                                  size=(self.WIDTH, self.HEIGHT))

    def _apply_dynamic_effect(
        self,
        clip: ImageClip,
        effect_type: str,
        duration: float,
    ) -> ImageClip:
        """
        ë‹¤ì´ë‚˜ë¯¹ íš¨ê³¼ ì ìš©
        - zoom_in: ì²œì²œíˆ ì¤Œì¸ (ê°•ì¡°)
        - zoom_out: ì¤Œì•„ì›ƒ (ì „ì²´ ìƒí™©)
        - shake: í™”ë©´ í”ë“¤ë¦¼ (ì¶©ê²©, ë†€ëŒ)
        - fade: í˜ì´ë“œ íš¨ê³¼ (ì¥ë©´ ì „í™˜)
        - static: íš¨ê³¼ ì—†ìŒ
        """
        import math

        # ì¤Œ ë²”ìœ„ (1.0 = ì›ë³¸, 1.15 = 15% í™•ëŒ€)
        zoom_start = 1.0
        zoom_end = 1.15

        def zoom_in_effect(t):
            """ì‹œê°„ì— ë”°ë¼ ì¤Œì¸"""
            progress = t / duration if duration > 0 else 0
            scale = zoom_start + (zoom_end - zoom_start) * progress
            return scale

        def zoom_out_effect(t):
            """ì‹œê°„ì— ë”°ë¼ ì¤Œì•„ì›ƒ"""
            progress = t / duration if duration > 0 else 0
            scale = zoom_end - (zoom_end - zoom_start) * progress
            return scale

        def shake_position(t):
            """í™”ë©´ í”ë“¤ë¦¼ íš¨ê³¼"""
            intensity = 8  # í”ë“¤ë¦¼ ê°•ë„ (í”½ì…€)
            frequency = 15  # í”ë“¤ë¦¼ ë¹ˆë„
            x = int(math.sin(t * frequency) * intensity)
            y = int(math.cos(t * frequency * 1.3) * intensity * 0.5)
            return (x, y)

        if effect_type == "zoom_in":
            return clip.resized(lambda t: zoom_in_effect(t))
        elif effect_type == "zoom_out":
            return clip.resized(lambda t: zoom_out_effect(t))
        elif effect_type == "shake":
            # í”ë“¤ë¦¼ + ì‚´ì§ ì¤Œì¸
            clip = clip.resized(1.05)
            return clip.with_position(shake_position)
        elif effect_type == "fade":
            # í˜ì´ë“œì¸ íš¨ê³¼
            return clip.with_effects([lambda c: c.crossfadein(0.3)])
        else:
            return clip

    def _resize_to_fit(self, clip: ImageClip) -> ImageClip:
        """Resize image clip to fit 9:16 - í™”ë©´ ê½‰ ì±„ìš°ê³  ìœ„ì•„ë˜ í¬ë¡­"""
        # í™”ë©´ì„ ê½‰ ì±„ìš°ê³  2ë°° í™•ëŒ€
        scale_w = self.WIDTH / clip.w
        scale_h = self.HEIGHT / clip.h
        scale = max(scale_w, scale_h) * 2.0  # 2ë°° í™•ëŒ€

        new_w = int(clip.w * scale)
        new_h = int(clip.h * scale)

        clip = clip.resized((new_w, new_h))

        # ì¤‘ì•™ ë°°ì¹˜ (í™”ë©´ ê½‰ ì±„ì›€)
        x_pos = (self.WIDTH - new_w) // 2
        y_pos = (self.HEIGHT - new_h) // 2

        return clip.with_position((x_pos, y_pos))

    def _create_title_clip(self, title: str, duration: float) -> list:
        """ìƒë‹¨ì— ì œëª© ì˜¤ë²„ë ˆì´ (ë°˜íˆ¬ëª… ë°°ê²½ + í°ìƒ‰ ê¸€ì”¨)"""

        # ì œëª©ì´ ë„ˆë¬´ ê¸¸ë©´ ìë¥´ê¸°
        if len(title) > 25:
            title = title[:22] + "..."

        title_clips = []

        # ì œëª© í…ìŠ¤íŠ¸
        main_title = TextClip(
            text=title,
            font_size=48,
            color="white",
            font="/System/Library/Fonts/AppleSDGothicNeo.ttc",
            method="caption",
            size=(self.WIDTH - 100, None),
            text_align="center",
            stroke_color="black",
            stroke_width=3,
        )

        # ì œëª© ë°°ê²½ ë°•ìŠ¤ (ë°˜íˆ¬ëª… ê²€ì •)
        title_w, title_h = main_title.size
        title_bg = ColorClip(
            size=(title_w + 40, title_h + 20),
            color=(0, 0, 0),
        ).with_opacity(0.6)

        # ìƒë‹¨ ë°°ì¹˜ (y=80)
        title_bg = title_bg.with_position(("center", 70))
        title_bg = title_bg.with_duration(duration)
        main_title = main_title.with_position(("center", 80))
        main_title = main_title.with_duration(duration)

        title_clips.append(title_bg)
        title_clips.append(main_title)

        return title_clips

    async def _generate_subtitles(
        self,
        script: Script,
        duration: float,
    ) -> list[TextClip]:
        """
        Generate animated subtitle clips - ìš”ì¦˜ ì‡¼ì¸  ìŠ¤íƒ€ì¼
        
        íŠ¹ì§•:
        - ì§§ê²Œ ì§§ê²Œ (2-4 ë‹¨ì–´ì”©)
        - ë¹ ë¥´ê²Œ ì „í™˜ (ë‹µë‹µí•˜ì§€ ì•Šê²Œ)
        - í•˜ë‹¨ safe zoneì— ë°°ì¹˜
        - í° ê¸€ì”¨ + í…Œë‘ë¦¬ (ê°€ë…ì„±)
        """
        subtitle_clips = []

        # ìŠ¤í¬ë¦½íŠ¸ë¥¼ ë¬¸ì¥ ë‹¨ìœ„ë¡œ ë¨¼ì € ë¶„ë¦¬
        text = script.full_text

        # ë”°ì˜´í‘œ ì œê±° (", ", â€˜, â€™, â€œ, â€ ë“±)
        text = text.replace('"', '').replace("'", '')
        text = text.replace('â€œ', '').replace('â€',
                                             '').replace('â€˜',
                                                         '').replace('â€™', '')

        # ë§ˆì¹¨í‘œ, ë¬¼ìŒí‘œ, ëŠë‚Œí‘œë¡œ ë¬¸ì¥ ë¶„ë¦¬
        import re
        sentences = re.split(r'(?<=[.?!])\s+', text)

        # ê° ë¬¸ì¥ì„ ì§§ì€ êµ¬ì ˆë¡œ ë¶„ë¦¬ (2-4 ë‹¨ì–´)
        phrases = []
        for sentence in sentences:
            words = sentence.split()

            # í•œêµ­ì–´ íŠ¹ì„±ìƒ 2-3 ë‹¨ì–´ê°€ ì ë‹¹ (ê¸´ ë‹¨ì–´ ë§ìŒ)
            chunk_size = 2 if any(len(w) > 5 for w in words) else 3

            for i in range(0, len(words), chunk_size):
                chunk = words[i:i + chunk_size]
                if chunk:
                    phrase = " ".join(chunk)
                    # ë„ˆë¬´ ì§§ì€ êµ¬ì ˆì€ ë‹¤ìŒê³¼ í•©ì¹˜ê¸°
                    if phrases and len(phrase) < 4 and len(phrases[-1]) < 15:
                        phrases[-1] += " " + phrase
                    else:
                        phrases.append(phrase)

        if not phrases:
            return subtitle_clips

        # ê° êµ¬ì ˆì˜ í‘œì‹œ ì‹œê°„ ê³„ì‚°
        # ìµœì†Œ 0.4ì´ˆ, ìµœëŒ€ 1.5ì´ˆ (ê¸€ììˆ˜ì— ë¹„ë¡€)
        total_chars = sum(len(p) for p in phrases)

        # ì‹œê°„ ë°°ë¶„
        phrase_times = []
        current_time = 0.0

        for phrase in phrases:
            # ê¸€ììˆ˜ ê¸°ë°˜ ì‹œê°„ (í•œ ê¸€ìë‹¹ ì•½ 0.08ì´ˆ, ìµœì†Œ 0.5ì´ˆ)
            char_time = len(phrase) * 0.08
            phrase_duration = max(0.5, min(1.5, char_time))

            phrase_times.append({
                "text": phrase,
                "start": current_time,
                "duration": phrase_duration
            })
            current_time += phrase_duration

        # ì „ì²´ ì‹œê°„ì— ë§ê²Œ ìŠ¤ì¼€ì¼ ì¡°ì •
        if current_time > 0:
            scale = duration / current_time
            for pt in phrase_times:
                pt["start"] *= scale
                pt["duration"] *= scale

        self.log(f"Creating {len(phrases)} subtitle segments")

        for pt in phrase_times:
            # ìë§‰ í…ìŠ¤íŠ¸ í´ë¦½ ìƒì„± (ë‘êº¼ìš´ ê¸€ì”¨ + í…Œë‘ë¦¬)
            txt_clip = TextClip(
                text=pt["text"],
                font_size=72,  # ë” í° ê¸€ì”¨
                color="white",
                font="/System/Library/Fonts/AppleSDGothicNeo.ttc",
                method="caption",
                size=(self.WIDTH - 160, None),
                text_align="center",
                stroke_color="black",  # ê²€ì • í…Œë‘ë¦¬
                stroke_width=3,  # í…Œë‘ë¦¬ ë‘ê»˜
            )

            # ê²€ì •ìƒ‰ ë°°ê²½ ë°•ìŠ¤ ìƒì„± (ë” í¬ê²Œ)
            txt_w, txt_h = txt_clip.size
            padding_x = 40  # ì¢Œìš° íŒ¨ë”©
            padding_y = 30  # ìƒí•˜ íŒ¨ë”©
            bg_clip = ColorClip(
                size=(txt_w + padding_x * 2, txt_h + padding_y * 2),
                color=(0, 0, 0),  # ê²€ì •ìƒ‰
            )

            # ë°°ê²½ + í…ìŠ¤íŠ¸ í•©ì¹˜ê¸°
            bg_clip = bg_clip.with_position(("center", self.HEIGHT * 0.72))
            txt_clip = txt_clip.with_position(
                ("center", self.HEIGHT * 0.72 + padding_y))

            bg_clip = bg_clip.with_start(pt["start"]).with_duration(
                pt["duration"])
            txt_clip = txt_clip.with_start(pt["start"]).with_duration(
                pt["duration"])

            subtitle_clips.append(bg_clip)
            subtitle_clips.append(txt_clip)

        return subtitle_clips

    def _create_gradient_background(self, duration: float) -> ColorClip:
        """Create a simple dark background"""
        return ColorClip(
            size=(self.WIDTH, self.HEIGHT),
            color=(15, 15, 20),
            duration=duration,
        )
