"""
ğŸ¨ Image Agent - Generates images using diffusers (local, no server needed)
"""

import asyncio
import random
from pathlib import Path
from typing import Optional

import httpx
import torch
from diffusers import StableDiffusionPipeline, DPMSolverMultistepScheduler
from PIL import Image

from ..models import ImageResult
from .base import BaseAgent


class ImageAgent(BaseAgent[list[ImageResult]]):
    """Agent for generating images with Stable Diffusion (diffusers)"""

    # Model path - MeinaMix V11 (ê¸€ë˜ë¨¸ ì˜¤í”¼ìŠ¤ ìŠ¤íƒ€ì¼)
    MODEL_PATH = Path.home(
    ) / "ComfyUI" / "models" / "checkpoints" / "meinamix_v11.safetensors"

    # HuggingFace fallback model
    HF_MODEL = "Meina/MeinaMix_V11"

    @property
    def name(self) -> str:
        return "ğŸ¨ ImageAgent"

    # ì˜ìƒ + ë°°ê²½ ë§¤ì¹­ (ìºì£¼ì–¼ ìœ„ì£¼)
    OUTFIT_BACKGROUND_PAIRS = [
        # ğŸ‘– ì²­ë°˜ë°”ì§€/ë°ë‹˜ (ì˜ ë½‘íˆëŠ” ìŠ¤íƒ€ì¼!)
        ("crop top, denim shorts",
         ["park, sunny day", "city street, summer", "ice cream shop"]),
        ("white t-shirt, denim shorts",
         ["cafe interior", "convenience store", "street, shopping"]),
        ("tank top, denim shorts",
         ["beach, summer", "pool party", "outdoor cafe"]),
        ("off-shoulder top, denim shorts",
         ["city street", "rooftop, sunny", "park, picnic"]),
        ("striped shirt, denim shorts",
         ["cafe terrace", "bookstore", "street, walking"]),

        # ğŸ‘• ìºì£¼ì–¼ ì¼ìƒ
        ("oversized t-shirt, shorts",
         ["room interior, bedroom", "living room, sofa", "convenience store"]),
        ("hoodie, mini skirt, sneakers",
         ["arcade, game center", "subway station", "street, night"]),
        ("casual dress, sneakers",
         ["park, sunny", "shopping mall", "cafe interior"]),
        ("cardigan, shorts, casual",
         ["cafe interior", "library", "street, autumn"]),

        # ğŸŒ ì—¬ë¦„ ìºì£¼ì–¼
        ("sleeveless top, hot pants",
         ["beach, sunset", "pool, summer", "rooftop, sunny"]),
        ("sundress, summer dress",
         ["flower field", "beach boardwalk", "outdoor cafe"]),
        ("bikini top, denim shorts",
         ["beach, ocean", "pool party", "resort, summer"]),
    ]

    # ì£¼ì¸ê³µ ì™¸ëª¨ ì˜µì…˜ (ì˜ìƒ ì‹œì‘ ì‹œ ëœë¤ ì„ íƒ í›„ ê³ ì •)
    # ëª¨ë“  ìºë¦­í„° ê²€ì€ ë¨¸ë¦¬ë¡œ í†µì¼
    HAIR_OPTIONS = [
        "long straight black hair",  # ê¸´ ìƒë¨¸ë¦¬
        "short black hair, bob cut",  # ë‹¨ë°œ
    ]

    FACE_OPTIONS = [
        "pretty face, makeup, black eyes",
        "beautiful face, light makeup, black eyes",
        "cute face, natural makeup, black eyes",
    ]

    # ê¸€ë˜ë¨¸ ìºë¦­í„° (ì£¼ì¸ê³µ = {protagonist}) - ì§§ê²Œ!
    CHARACTER_TEMPLATES = [
        # ì£¼ì¸ê³µ í˜¼ì
        ("1girl, {protagonist}, {outfit}", 60),
        # ì£¼ì¸ê³µ + ë‹¤ë¥¸ ì—¬ì
        ("2girls, {protagonist}, another girl, {outfit}", 15),
        # ì£¼ì¸ê³µ + ë‚¨ì
        ("1boy 1girl, {protagonist}, handsome man", 15),
        # í´ë¡œì¦ˆì—…
        ("1girl, {protagonist}, upper body, face focus", 10),
    ]

    # í”„ë¡¬í”„íŠ¸ (ê°„ê²°í•˜ê²Œ - CLIP 77í† í° ì œí•œ)
    QUALITY_PROMPT = "masterpiece, best quality, korean webtoon"

    NEGATIVE_PROMPT = """
    ugly, deformed, noisy, blurry, low quality,
    bad anatomy, bad proportions, watermark, text,
    realistic, photo, nsfw, nude, naked, explicit,
    extra fingers, mutated hands, poorly drawn face,
    flat chest, child, loli, underage
    """.strip()

    def __init__(self):
        super().__init__()
        self._pipe: Optional[StableDiffusionPipeline] = None
        self._protagonist: Optional[str] = None  # ì£¼ì¸ê³µ ìºë¦­í„° (ì˜ìƒë§ˆë‹¤ ê³ ì •)
        self._protagonist_seed: Optional[int] = None  # ì£¼ì¸ê³µ seed (ì¼ê´€ì„±)

    def _load_pipeline(self) -> StableDiffusionPipeline:
        """Load the Stable Diffusion pipeline (lazy loading)"""
        if self._pipe is not None:
            return self._pipe

        self.log(
            "Loading Counterfeit V3 model (first time may take a while)...")

        # Check for Apple Silicon MPS
        if torch.backends.mps.is_available():
            device = "mps"
            # MPSì—ì„œëŠ” float32ê°€ ë” ì•ˆì •ì 
            dtype = torch.float32
            self.log("Using Apple Silicon MPS acceleration ğŸ")
        elif torch.cuda.is_available():
            device = "cuda"
            dtype = torch.float16
            self.log("Using NVIDIA CUDA acceleration ğŸŸ¢")
        else:
            device = "cpu"
            dtype = torch.float32
            self.log("Using CPU (this will be slow) ğŸ¢")

        # Try local model first, then HuggingFace
        if self.MODEL_PATH.exists():
            self.log(f"Loading local model: {self.MODEL_PATH.name}")
            self._pipe = StableDiffusionPipeline.from_single_file(
                str(self.MODEL_PATH),
                torch_dtype=dtype,
                use_safetensors=True,
            )
        else:
            self.log(
                f"Local model not found, downloading from HuggingFace: {self.HF_MODEL}"
            )
            self._pipe = StableDiffusionPipeline.from_pretrained(
                self.HF_MODEL,
                torch_dtype=dtype,
                use_safetensors=True,
            )

        # Use faster scheduler
        self._pipe.scheduler = DPMSolverMultistepScheduler.from_config(
            self._pipe.scheduler.config)

        self._pipe = self._pipe.to(device)

        # Memory optimization
        self._pipe.enable_attention_slicing()

        self.log("Model loaded successfully! âœ¨")
        return self._pipe

    def _create_protagonist(self) -> str:
        """ì˜ìƒ ì‹œì‘ ì‹œ ì£¼ì¸ê³µ ì™¸ëª¨ ìƒì„± (í•œ ë²ˆë§Œ) - ì§§ê²Œ!"""
        hair = random.choice(self.HAIR_OPTIONS)
        # ê°„ê²°í•˜ê²Œ: ë¨¸ë¦¬ + ëª¸ë§¤ë§Œ
        protagonist = f"{hair}, pretty face, large breasts"
        self.log(f"ğŸ­ ì£¼ì¸ê³µ: {hair}")
        return protagonist

    def _pick_outfit_and_background(self) -> tuple[str, str]:
        """ì˜ìƒê³¼ ì–´ìš¸ë¦¬ëŠ” ë°°ê²½ì„ í•¨ê»˜ ì„ íƒ"""
        outfit, backgrounds = random.choice(self.OUTFIT_BACKGROUND_PAIRS)
        background = random.choice(backgrounds)
        return outfit, background

    def _pick_character_template(self, scene_prompt: str = "") -> str:
        """ì”¬ ë‚´ìš©ì— ë§ëŠ” ìºë¦­í„° í…œí”Œë¦¿ ì„ íƒ - ì”¬ í”„ë¡¬í”„íŠ¸ê°€ ì£¼ì¸ê³µì¼ ë•Œë§Œ ìºë¦­í„° ì¶”ê°€"""
        scene_lower = scene_prompt.lower()

        # ì”¬ ë‚´ìš© ë¶„ì„í•´ì„œ ìºë¦­í„° êµ¬ì„± ê²°ì •
        has_man = any(word in scene_lower for word in [
            "man", "boy", "guy", "boyfriend", "husband", "male", "he ", "him",
            "his", "couple"
        ])
        has_two_girls = any(word in scene_lower for word in [
            "two girls", "2 girls", "friends", "girls talking", "both girls",
            "2girls"
        ])

        # ì”¬ì— ì´ë¯¸ ì˜ìƒ/ì§ì—…ì´ ìˆëŠ”ì§€ í™•ì¸
        has_outfit_in_scene = any(word in scene_lower for word in [
            "uniform", "dress", "outfit", "wearing", "clothes", "suit",
            "attendant", "nurse", "maid", "teacher", "student", "office",
            "bikini", "swimsuit", "pajamas", "coat", "jacket"
        ])

        # ìºë¦­í„° êµ¬ì„±ë§Œ ê²°ì • (ì˜ìƒì€ ì”¬ì—ì„œ ê°€ì ¸ì˜´)
        if has_man:
            # ë‚¨ìê°€ ë‚˜ì˜¤ëŠ” ì”¬
            char = f"1boy 1girl, {self._protagonist}, handsome man"
        elif has_two_girls:
            # ì—¬ì ë‘˜
            char = f"2girls, {self._protagonist}, another girl"
        else:
            # ê¸°ë³¸ 1girl
            char = f"1girl, {self._protagonist}"

        # ì”¬ì— ì˜ìƒì´ ì—†ìœ¼ë©´ ëœë¤ ì˜ìƒ ì¶”ê°€
        if not has_outfit_in_scene:
            outfit, _ = self._pick_outfit_and_background()
            char = f"{char}, {outfit}"

        return char

    async def run(
            self,
            prompts: list[str],
            output_dir: Path,
            character_prompt: Optional[str] = None,
            width: int = 512,  # SD 1.5 í•´ìƒë„
            height: int = 680,  # ë” í¬ë¡­ë˜ê²Œ (ìœ„ì•„ë˜ ë§ì´ ì˜ë¦¼)
    ) -> list[ImageResult]:
        """Generate multiple images for the video"""

        self.log(f"Generating {len(prompts)} images...")

        # ğŸ­ ì˜ìƒë§ˆë‹¤ ì£¼ì¸ê³µ ìºë¦­í„° ìƒˆë¡œ ìƒì„± (ì´ ì˜ìƒ ë‚´ì—ì„œëŠ” ê³ ì •)
        self._protagonist = self._create_protagonist()
        self._protagonist_seed = random.randint(1, 999999)
        self.log(f"ğŸ² ì£¼ì¸ê³µ seed: {self._protagonist_seed}")

        output_dir = Path(output_dir)
        output_dir.mkdir(parents=True, exist_ok=True)

        results = []

        # Load pipeline once
        pipe = self._load_pipeline()

        for i, scene_prompt in enumerate(prompts):
            # ì¹´ë©”ë¼ íš¨ê³¼ì™€ í”„ë¡¬í”„íŠ¸ ë¶„ë¦¬ (format: "effect|prompt")
            effect = "static"
            actual_prompt = scene_prompt
            if "|" in scene_prompt:
                parts = scene_prompt.split("|", 1)
                effect = parts[0].strip()
                actual_prompt = parts[1].strip()

            # ì”¬ ë‚´ìš© ë¶„ì„í•´ì„œ ì ì ˆí•œ ìºë¦­í„° êµ¬ì„± ì„ íƒ
            if character_prompt:
                char_prompt = character_prompt
            else:
                char_prompt = self._pick_character_template(actual_prompt)

            # í”„ë¡¬í”„íŠ¸ ìˆœì„œ: ì”¬ ë‚´ìš© > ìºë¦­í„° > í€„ë¦¬í‹° (CLIPì€ ì•ë¶€ë¶„ ìš°ì„ )
            full_prompt = f"{actual_prompt}, {char_prompt}, {self.QUALITY_PROMPT}"

            self.log(f"Generating image {i+1}/{len(prompts)} [{effect}]...")
            self.log(f"  ğŸ“ Scene: {actual_prompt}")
            self.log(f"  ğŸ¨ Full prompt: {full_prompt[:100]}...")

            image_path = output_dir / f"image_{i:03d}.png"

            try:
                # Run generation in thread pool (sync -> async)
                image = await asyncio.get_event_loop().run_in_executor(
                    None, lambda: self._generate_sync(pipe, full_prompt, width,
                                                      height))

                # Resize to shorts format (9:16) - 1080x1920
                shorts_image = self._resize_for_shorts(image)
                shorts_image.save(image_path)

                # íš¨ê³¼ ì •ë³´ë¥¼ í”„ë¡¬í”„íŠ¸ ì•ì— ìœ ì§€ (video_agentì—ì„œ ì‚¬ìš©)
                results.append(
                    ImageResult(
                        file_path=image_path,
                        prompt=f"{effect}|{actual_prompt}",
                        index=i,
                    ))
                self.log(f"âœ“ Image {i+1} saved")
            except Exception as e:
                self.log(f"Failed to generate image {i}: {e}")

        self.log(f"Generated {len(results)} images")
        return results

    def _generate_sync(
        self,
        pipe: StableDiffusionPipeline,
        prompt: str,
        width: int,
        height: int,
        use_protagonist_seed: bool = True,
    ) -> Image.Image:
        """Synchronous image generation (called in thread pool)"""
        # ì£¼ì¸ê³µì´ ë‚˜ì˜¤ëŠ” ì”¬ì€ ê°™ì€ seed ì‚¬ìš© (ì¼ê´€ì„±)
        generator = None
        if use_protagonist_seed and self._protagonist_seed:
            # seedì— ì•½ê°„ì˜ ë³€í™”ë¥¼ ì¤˜ì„œ ì™„ì „ ë˜‘ê°™ì§„ ì•Šê²Œ
            seed = self._protagonist_seed + random.randint(0, 100)
            generator = torch.Generator().manual_seed(seed)

        result = pipe(
            prompt=prompt,
            negative_prompt=self.NEGATIVE_PROMPT,
            width=width,
            height=height,
            num_inference_steps=25,
            guidance_scale=7.0,
            generator=generator,
        )
        return result.images[0]

    def _resize_for_shorts(self, image: Image.Image) -> Image.Image:
        """
        Resize image for YouTube Shorts - ê°€ë¡œ ê½‰ ì±„ìš°ê³  ìœ„ì•„ë˜ ìë¥´ê¸°
        """
        target_w, target_h = 1080, 1920

        img_w, img_h = image.size

        # ê°€ë¡œë¥¼ ê½‰ ì±„ìš°ê³  ìœ„ì•„ë˜ crop
        scale = target_w / img_w
        new_w = target_w
        new_h = int(img_h * scale)

        resized = image.resize((new_w, new_h), Image.Resampling.LANCZOS)

        # ìœ„ì•„ë˜ ìë¥´ê¸° (ì¤‘ì•™ ê¸°ì¤€)
        if new_h > target_h:
            # ìœ„ì•„ë˜ crop
            top = (new_h - target_h) // 2
            cropped = resized.crop((0, top, target_w, top + target_h))
        else:
            # ì„¸ë¡œê°€ ë¶€ì¡±í•˜ë©´ ê²€ì€ ë°°ê²½ì— ì¤‘ì•™ ë°°ì¹˜
            canvas = Image.new('RGB', (target_w, target_h), (0, 0, 0))
            y = (target_h - new_h) // 2
            canvas.paste(resized, (0, y))
            cropped = canvas

        return cropped

    async def search_and_download_image(
        self,
        query: str,
        output_path: Path,
    ) -> Optional[Path]:
        """
        Unsplashì—ì„œ ë¬´ë£Œ ì´ë¯¸ì§€ ê²€ìƒ‰ & ë‹¤ìš´ë¡œë“œ
        ì£¼ì œì— ë§ëŠ” ì‹¤ì œ ì´ë¯¸ì§€ (ì€ìˆ˜ì €, ì¹´í˜, í—¬ìŠ¤ì¥ ë“±)
        """
        self.log(f"Searching image for: {query}")

        try:
            # Unsplash API (ë¬´ë£Œ, API í‚¤ ë¶ˆí•„ìš”í•œ ë°©ì‹)
            async with httpx.AsyncClient(timeout=30) as client:
                # ê²€ìƒ‰ URL (source.unsplash.com ë¦¬ë‹¤ì´ë ‰íŠ¸ ì‚¬ìš©)
                search_url = f"https://source.unsplash.com/800x600/?{query}"

                response = await client.get(search_url, follow_redirects=True)

                if response.status_code == 200:
                    # ì´ë¯¸ì§€ ì €ì¥
                    output_path.parent.mkdir(parents=True, exist_ok=True)

                    with open(output_path, "wb") as f:
                        f.write(response.content)

                    # ì‡¼ì¸  í¬ë§·ìœ¼ë¡œ ë¦¬ì‚¬ì´ì¦ˆ
                    img = Image.open(output_path)
                    resized = self._resize_for_shorts(img)
                    resized.save(output_path)

                    self.log(f"âœ“ Downloaded: {query}")
                    return output_path

        except Exception as e:
            self.log(f"Failed to search image: {e}")

        return None

    async def get_topic_image(
        self,
        topic: str,
        output_dir: Path,
    ) -> Optional[ImageResult]:
        """
        ì£¼ì œì— ë§ëŠ” ëŒ€í‘œ ì´ë¯¸ì§€ ê°€ì ¸ì˜¤ê¸°
        ì˜ˆ: "ì€ìˆ˜ì €" â†’ ì€ìˆ˜ì € ì´ë¯¸ì§€, "ì¹´í˜" â†’ ì¹´í˜ ì´ë¯¸ì§€
        """
        # í•œêµ­ì–´ â†’ ì˜ì–´ í‚¤ì›Œë“œ ë§¤í•‘ (ê²€ìƒ‰ìš©)
        keyword_map = {
            "ì€ìˆ˜ì €": "silver spoon wealth",
            "ê¸ˆìˆ˜ì €": "gold spoon luxury",
            "í™ìˆ˜ì €": "poor struggle",
            "ì¹´í˜": "coffee shop barista",
            "í—¬ìŠ¤ì¥": "gym fitness",
            "íšŒì‚¬": "office workplace",
            "ì§ì¥": "corporate office",
            "ì•Œë°”": "part time job",
            "ì—°ì• ": "couple love",
            "ì¸": "romantic dating",
            "ì¹œêµ¬": "friendship friends",
            "ê°€ì¡±": "family",
            "í•™êµ": "school student",
            "ëŒ€í•™": "university college",
            "ë©´ì ‘": "job interview",
            "ì´ì§": "career change",
            "í‡´ì‚¬": "quit job resignation",
            "ì›”ê¸‰": "salary paycheck money",
            "ë¶€ì": "rich wealthy luxury",
            "ì—¬í–‰": "travel vacation",
        }

        # ì£¼ì œì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ
        search_query = None
        for korean, english in keyword_map.items():
            if korean in topic:
                search_query = english
                break

        if not search_query:
            # ë§¤í•‘ ì—†ìœ¼ë©´ ì£¼ì œ ê·¸ëŒ€ë¡œ ì‚¬ìš©
            search_query = topic

        output_path = output_dir / "topic_image.png"
        result = await self.search_and_download_image(search_query,
                                                      output_path)

        if result:
            return ImageResult(
                file_path=result,
                prompt=f"searched: {search_query}",
                index=-1,
            )

        return None
